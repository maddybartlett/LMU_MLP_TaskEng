{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pytry\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "import researchpy as rp\n",
    "from scipy.stats import norm\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrraw_clip = pd.read_pickle(\"./lrraw_clip.pkl\") #logistic regression without lmus\n",
    "lrlmu_clip = pd.read_pickle(\"./lrlmu_clip.pkl\") #logistic regression with lmus\n",
    "mlpraw_clip = pd.read_pickle(\"./mlpraw_clip.pkl\") #mlp without lmus\n",
    "mlplmu_clip = pd.read_pickle(\"./mlplmu_clip.pkl\") #mlp without lmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame-by-Frame Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrraw_highframes=[]\n",
    "lrraw_midframes=[]\n",
    "lrraw_lowframes=[]\n",
    "lrraw_randframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(lrraw_clip['prediction_prob_high'][i])\n",
    "    lrraw_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(lrraw_clip['prediction_prob_mid'][i])\n",
    "    lrraw_midframes.append(b)\n",
    "    \n",
    "    c=np.vstack(lrraw_clip['prediction_prob_low'][i])\n",
    "    lrraw_lowframes.append(c)\n",
    "    \n",
    "    d=np.vstack(lrraw_clip['prediction_prob_random'][i])\n",
    "    lrraw_randframes.append(d)\n",
    "    \n",
    "lrraw_highframes_all = np.vstack(lrraw_highframes)\n",
    "lrraw_midframes_all = np.vstack(lrraw_midframes)\n",
    "lrraw_lowframes_all = np.vstack(lrraw_lowframes)\n",
    "lrraw_randframes_all = np.vstack(lrraw_randframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.04, 'Probability of High Engagement')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x324 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = probability of high engagement, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(lrraw_highframes_all[:,1], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Frames')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(lrraw_midframes_all[:,1], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Frames')\n",
    "(nl, bins, plot) = ax3.hist(lrraw_lowframes_all[:,1], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Frames')\n",
    "ax4.hist(lrraw_randframes_all[:,1], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Frames')\n",
    "\n",
    "lrrhigh_cor = (nh[9]/len(lrraw_highframes_all))*100\n",
    "lrrmid_cor = (nm[5]/len(lrraw_midframes_all))*100\n",
    "lrrlow_cor = (nl[0]/len(lrraw_lowframes_all))*100\n",
    "\n",
    "fig.suptitle('Logistic Regression without LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Probability of High Engagement', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR With LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrlmu_highframes=[]\n",
    "lrlmu_midframes=[]\n",
    "lrlmu_lowframes=[]\n",
    "lrlmu_randframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(lrlmu_clip['prediction_prob_high'][i])\n",
    "    lrlmu_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(lrlmu_clip['prediction_prob_mid'][i])\n",
    "    lrlmu_midframes.append(b)\n",
    "    \n",
    "    c=np.vstack(lrlmu_clip['prediction_prob_low'][i])\n",
    "    lrlmu_lowframes.append(c)\n",
    "    \n",
    "    d=np.vstack(lrlmu_clip['prediction_prob_random'][i])\n",
    "    lrlmu_randframes.append(d)\n",
    "    \n",
    "lrlmu_highframes_all = np.vstack(lrlmu_highframes)\n",
    "lrlmu_midframes_all = np.vstack(lrlmu_midframes)\n",
    "lrlmu_lowframes_all = np.vstack(lrlmu_lowframes)\n",
    "lrlmu_randframes_all = np.vstack(lrlmu_randframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = probability of high engagement, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(lrlmu_highframes_all[:,1], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Frames')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(lrlmu_midframes_all[:,1], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Frames')\n",
    "(nl, bins, plot) = ax3.hist(lrlmu_lowframes_all[:,1], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Frames')\n",
    "ax4.hist(lrlmu_randframes_all[:,1], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Frames')\n",
    "\n",
    "lrlhigh_cor = (nh[9]/len(lrlmu_highframes_all))*100\n",
    "lrlmid_cor = (nm[5]/len(lrlmu_midframes_all))*100\n",
    "lrllow_cor = (nl[0]/len(lrlmu_lowframes_all))*100\n",
    "\n",
    "fig.suptitle('Logistic Regression with LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Probability of High Engagement', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpraw_highframes=[]\n",
    "mlpraw_midframes=[]\n",
    "mlpraw_lowframes=[]\n",
    "mlpraw_randframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(mlpraw_clip['decision_high'][i])\n",
    "    mlpraw_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(mlpraw_clip['decision_mid'][i])\n",
    "    mlpraw_midframes.append(b)\n",
    "    \n",
    "    c=np.vstack(mlpraw_clip['decision_low'][i])\n",
    "    mlpraw_lowframes.append(c)\n",
    "    \n",
    "    d=np.vstack(mlpraw_clip['decision_random'][i])\n",
    "    mlpraw_randframes.append(d)\n",
    "    \n",
    "mlpraw_highframes_all = np.vstack(mlpraw_highframes)\n",
    "mlpraw_midframes_all = np.vstack(mlpraw_midframes)\n",
    "mlpraw_lowframes_all = np.vstack(mlpraw_lowframes)\n",
    "mlpraw_randframes_all = np.vstack(mlpraw_randframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = decision score, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(mlpraw_highframes_all[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Frames')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(mlpraw_midframes_all[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Frames')\n",
    "(nl, bins, plot) = ax3.hist(mlpraw_lowframes_all[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Frames')\n",
    "ax4.hist(mlpraw_randframes_all[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Frames')\n",
    "\n",
    "mlprhigh_cor = (nh[9]/len(mlpraw_highframes_all))*100\n",
    "mlprmid_cor = (nm[5]/len(mlpraw_midframes_all))*100\n",
    "mlprlow_cor = (nl[0]/len(mlpraw_lowframes_all))*100\n",
    "\n",
    "fig.suptitle('MLP without LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Decision Score', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP With LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlplmu_highframes=[]\n",
    "mlplmu_midframes=[]\n",
    "mlplmu_lowframes=[]\n",
    "mlplmu_randframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(mlplmu_clip['decision_high'][i])\n",
    "    mlplmu_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(mlplmu_clip['decision_mid'][i])\n",
    "    mlplmu_midframes.append(b)\n",
    "    \n",
    "    c=np.vstack(mlplmu_clip['decision_low'][i])\n",
    "    mlplmu_lowframes.append(c)\n",
    "    \n",
    "    d=np.vstack(mlplmu_clip['decision_random'][i])\n",
    "    mlplmu_randframes.append(d)\n",
    "    \n",
    "mlplmu_highframes_all = np.vstack(mlplmu_highframes)\n",
    "mlplmu_midframes_all = np.vstack(mlplmu_midframes)\n",
    "mlplmu_lowframes_all = np.vstack(mlplmu_lowframes)\n",
    "mlplmu_randframes_all = np.vstack(mlplmu_randframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = decision score, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(mlplmu_highframes_all[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Frames')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(mlplmu_midframes_all[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Frames')\n",
    "(nl, bins, plot) = ax3.hist(mlplmu_lowframes_all[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Frames')\n",
    "ax4.hist(mlplmu_randframes_all[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Frames')\n",
    "\n",
    "mlplhigh_cor = (nh[9]/len(mlplmu_highframes_all))*100\n",
    "mlplmid_cor = (nm[5]/len(mlplmu_midframes_all))*100\n",
    "mlpllow_cor = (nl[0]/len(mlplmu_lowframes_all))*100\n",
    "\n",
    "fig.suptitle('MLP with LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Decision Score', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Percent_Correct_Frames = pd.DataFrame({'LR w/o LMU % Correct': [f'{lrrhigh_cor:.2f}'+'%',\n",
    "                                                  f'{lrrmid_cor:.2f}'+'%',\n",
    "                                                  f'{lrrlow_cor:.2f}'+'%'],\n",
    "                                'LR with LMU % Correct': [f'{lrlhigh_cor:.2f}'+'%',\n",
    "                                                  f'{lrlmid_cor:.2f}'+'%',\n",
    "                                                  f'{lrllow_cor:.2f}'+'%'],\n",
    "                                'MLP w/o LMU % Correct': [f'{mlprhigh_cor:.2f}'+'%',\n",
    "                                                  f'{mlprmid_cor:.2f}'+'%',\n",
    "                                                  f'{mlprlow_cor:.2f}'+'%'],\n",
    "                                'MLP with LMU % Correct': [f'{lrlhigh_cor:.2f}'+'%',\n",
    "                                                  f'{mlplmid_cor:.2f}'+'%',\n",
    "                                                  f'{mlpllow_cor:.2f}'+'%']})\n",
    "\n",
    "Percent_Correct_Frames.set_index([pd.Index(['High Engagement', 'Intermediate Engagement', 'Low Engagement'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Output for each Clip separated by Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and Collect Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression without LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of probability of high engagement classification over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(lrraw_clip)):\n",
    "    for i in range(18):\n",
    "        mean=lrraw_clip.iloc[j]['prediction_prob_high'][i][:,1].mean()\n",
    "        std=lrraw_clip.iloc[j]['prediction_prob_high'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw_clip.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw_clip.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=lrraw_clip.iloc[j]['prediction_prob_mid'][i][:,1].mean()\n",
    "        std=lrraw_clip.iloc[j]['prediction_prob_mid'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw_clip.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw_clip.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrraw_clip.iloc[j]['prediction_prob_low'][i][:,1].mean()\n",
    "        std=lrraw_clip.iloc[j]['prediction_prob_low'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw_clip.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw_clip.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrraw_clip.iloc[j]['prediction_prob_random'][i][:,1].mean()\n",
    "        std=lrraw_clip.iloc[j]['prediction_prob_random'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw_clip.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw_clip.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_lrraw_summary=np.asarray(high_summary)\n",
    "mid_lrraw_summary=np.asarray(mid_summary)\n",
    "low_lrraw_summary=np.asarray(low_summary)\n",
    "random_lrraw_summary=np.asarray(random_summary)\n",
    "summaries_lrraw=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of probability of high engagement classification over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(lrlmu_clip)):\n",
    "    for i in range(18):\n",
    "        mean=lrlmu_clip.iloc[j]['prediction_prob_high'][i][:,1].mean()\n",
    "        std=lrlmu_clip.iloc[j]['prediction_prob_high'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu_clip.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu_clip.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=lrlmu_clip.iloc[j]['prediction_prob_mid'][i][:,1].mean()\n",
    "        std=lrlmu_clip.iloc[j]['prediction_prob_mid'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu_clip.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu_clip.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrlmu_clip.iloc[j]['prediction_prob_low'][i][:,1].mean()\n",
    "        std=lrlmu_clip.iloc[j]['prediction_prob_low'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu_clip.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu_clip.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrlmu_clip.iloc[j]['prediction_prob_random'][i][:,1].mean()\n",
    "        std=lrlmu_clip.iloc[j]['prediction_prob_random'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu_clip.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu_clip.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_lrlmu_summary=np.asarray(high_summary)\n",
    "mid_lrlmu_summary=np.asarray(mid_summary)\n",
    "low_lrlmu_summary=np.asarray(low_summary)\n",
    "random_lrlmu_summary=np.asarray(random_summary)\n",
    "summaries_lrlmu=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP without LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of the decision values over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(mlpraw_clip)):\n",
    "    for i in range(18):\n",
    "        mean=mlpraw_clip.iloc[j]['decision_high'][i][:,0].mean()\n",
    "        std=mlpraw_clip.iloc[j]['decision_high'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw_clip.iloc[j]['decision_high'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw_clip.iloc[j]['decision_high'][i][:,0])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=mlpraw_clip.iloc[j]['decision_mid'][i][:,0].mean()\n",
    "        std=mlpraw_clip.iloc[j]['decision_mid'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw_clip.iloc[j]['decision_mid'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw_clip.iloc[j]['decision_mid'][i][:,0])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlpraw_clip.iloc[j]['decision_low'][i][:,0].mean()\n",
    "        std=mlpraw_clip.iloc[j]['decision_low'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw_clip.iloc[j]['decision_low'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw_clip.iloc[j]['decision_low'][i][:,0])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlpraw_clip.iloc[j]['decision_random'][i][:,0].mean()\n",
    "        std=mlpraw_clip.iloc[j]['decision_random'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw_clip.iloc[j]['decision_random'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw_clip.iloc[j]['decision_random'][i][:,0])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_mlpraw_summary=np.asarray(high_summary)\n",
    "mid_mlpraw_summary=np.asarray(mid_summary)\n",
    "low_mlpraw_summary=np.asarray(low_summary)\n",
    "random_mlpraw_summary=np.asarray(random_summary)\n",
    "summaries_mlpraw=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of the decision values over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(mlplmu_clip)):\n",
    "    for i in range(18):\n",
    "        mean=mlplmu_clip.iloc[j]['decision_high'][i][:,0].mean()\n",
    "        std=mlplmu_clip.iloc[j]['decision_high'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu_clip.iloc[j]['decision_high'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu_clip.iloc[j]['decision_high'][i][:,0])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=mlplmu_clip.iloc[j]['decision_mid'][i][:,0].mean()\n",
    "        std=mlplmu_clip.iloc[j]['decision_mid'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu_clip.iloc[j]['decision_mid'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu_clip.iloc[j]['decision_mid'][i][:,0])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlplmu_clip.iloc[j]['decision_low'][i][:,0].mean()\n",
    "        std=mlplmu_clip.iloc[j]['decision_low'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu_clip.iloc[j]['decision_low'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu_clip.iloc[j]['decision_low'][i][:,0])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlplmu_clip.iloc[j]['decision_random'][i][:,0].mean()\n",
    "        std=mlplmu_clip.iloc[j]['decision_random'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu_clip.iloc[j]['decision_random'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu_clip.iloc[j]['decision_random'][i][:,0])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_mlplmu_summary=np.asarray(high_summary)\n",
    "mid_mlplmu_summary=np.asarray(mid_summary)\n",
    "low_mlplmu_summary=np.asarray(low_summary)\n",
    "random_mlplmu_summary=np.asarray(random_summary)\n",
    "summaries_mlplmu=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the mean probability that each test clip would be \n",
    "#classed as Noplay across all 20 experiments\n",
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = mean prediction probability, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(high_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Clips')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(mid_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Clips')\n",
    "(nl, bins, plot) = ax3.hist(low_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Clips')\n",
    "ax4.hist(random_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Clips')\n",
    "\n",
    "lrrhigh_cor = (nh[9]/len(high_lrraw_summary))*100\n",
    "lrrmid_cor = (nm[5]/len(mid_lrraw_summary))*100\n",
    "lrrlow_cor = (nl[0]/len(low_lrraw_summary))*100\n",
    "\n",
    "fig.suptitle('Logistic Regression without LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Mean Probability of High', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression With LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the mean probability that each test clip would be \n",
    "#classed as Noplay across all 20 experiments\n",
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = mean prediction probability, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(high_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Clips')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(mid_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Clips')\n",
    "(nl, bins, plot) = ax3.hist(low_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Clips')\n",
    "ax4.hist(random_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Clips')\n",
    "\n",
    "lrlhigh_cor = (nh[9]/len(high_lrlmu_summary))*100\n",
    "lrlmid_cor = (nm[5]/len(mid_lrlmu_summary))*100\n",
    "lrllow_cor = (nl[0]/len(low_lrlmu_summary))*100\n",
    "\n",
    "fig.suptitle('Logistic Regression with LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Mean Probability of High', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the mean decision value for each clip\n",
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = mean decision value, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(high_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Clips')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(mid_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Clips')\n",
    "(nl, bins, plot) = ax3.hist(low_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Clips')\n",
    "ax4.hist(random_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Clips')\n",
    "\n",
    "mlprhigh_cor = (nh[9]/len(high_mlpraw_summary))*100\n",
    "mlprmid_cor = (nm[5]/len(mid_mlpraw_summary))*100\n",
    "mlprlow_cor = (nl[0]/len(low_mlpraw_summary))*100\n",
    "\n",
    "fig.suptitle('MLP without LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Mean Decision Value', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP With LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the mean decision value for each clip\n",
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = mean decision value, y-axis = count\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "(nh, bins, plot) = ax1.hist(high_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Clips')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "(nm, bins, plot) = ax2.hist(mid_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Clips')\n",
    "(nl, bins, plot) = ax3.hist(low_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Clips')\n",
    "ax4.hist(random_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Clips')\n",
    "\n",
    "mlplhigh_cor = (nh[9]/len(high_mlplmu_summary))*100\n",
    "mlplmid_cor = (nm[5]/len(mid_mlplmu_summary))*100\n",
    "mlpllow_cor = (nl[0]/len(low_mlplmu_summary))*100\n",
    "\n",
    "fig.suptitle('MLP with LMUs', fontsize=14)\n",
    "fig.text(0.5, 0.04, 'Mean Decision Value', ha='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Percent_Correct_Clips = pd.DataFrame({'LR w/o LMU % Correct': [f'{lrrhigh_cor:.2f}'+'%',\n",
    "                                                  f'{lrrmid_cor:.2f}'+'%',\n",
    "                                                  f'{lrrlow_cor:.2f}'+'%'],\n",
    "                                'LR with LMU % Correct': [f'{lrlhigh_cor:.2f}'+'%',\n",
    "                                                  f'{lrlmid_cor:.2f}'+'%',\n",
    "                                                  f'{lrllow_cor:.2f}'+'%'],\n",
    "                                'MLP w/o LMU % Correct': [f'{mlprhigh_cor:.2f}'+'%',\n",
    "                                                  f'{mlprmid_cor:.2f}'+'%',\n",
    "                                                  f'{mlprlow_cor:.2f}'+'%'],\n",
    "                                'MLP with LMU % Correct': [f'{lrlhigh_cor:.2f}'+'%',\n",
    "                                                  f'{mlplmid_cor:.2f}'+'%',\n",
    "                                                  f'{mlpllow_cor:.2f}'+'%']})\n",
    "\n",
    "Percent_Correct_Clips.set_index([pd.Index(['High Engagement', 'Intermediate Engagement', 'Low Engagement'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Output across Clip Timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Without LMUs\n",
    "Plot probability of high classification across timeline of each clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for j in range(20): # for each experiment create 1 plot    \n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=(15, 4.5))\n",
    "    for i in range(18): # for each clip plot 1 line\n",
    "        a=lrraw_clip.iloc[j]['prediction_prob_high'][i]\n",
    "        ax1.plot(a[:,1])\n",
    "        ax1.set_xlim(0,1000)\n",
    "        ax1.set_ylabel('Probability of High', fontsize=12)\n",
    "        ax1.set_xlabel('Frame', fontsize=12)\n",
    "        ax1.title.set_text('High Clips Exp %s' % j)\n",
    "        \n",
    "        b=lrraw_clip.iloc[j]['prediction_prob_mid'][i]\n",
    "        ax2.plot(b[:,1])\n",
    "        ax2.set_xlim(0,1000)\n",
    "        ax2.set_xlabel('Frame', fontsize=12)\n",
    "        ax2.title.set_text('Intermediate Clips Exp %s' % j)\n",
    "        \n",
    "        c=lrraw_clip.iloc[j]['prediction_prob_low'][i]\n",
    "        ax3.plot(c[:,1])\n",
    "        ax3.set_xlim(0,1000)\n",
    "        ax3.set_xlabel('Frame', fontsize=12)\n",
    "        ax3.title.set_text('Low Clips Exp %s' % j)\n",
    "        \n",
    "        d=lrraw_clip.iloc[j]['prediction_prob_random'][i]\n",
    "        ax4.plot(d[:,1])\n",
    "        ax4.set_xlim(0,1000)\n",
    "        ax4.set_xlabel('Frame', fontsize=12)\n",
    "        ax4.title.set_text('Random Clips Exp %s' % j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression With LMUs\n",
    "Plot probability of high classification across timeline of each clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(20): # for each experiment create 1 plot    \n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=(15, 4.5))\n",
    "    for i in range(18): # for each clip plot 1 line\n",
    "        a=lrlmu_clip.iloc[j]['prediction_prob_high'][i]\n",
    "        ax1.plot(a[:,1])\n",
    "        ax1.set_xlim(0,1000)\n",
    "        ax1.set_ylabel('Probability of High', fontsize=12)\n",
    "        ax1.set_xlabel('Frame', fontsize=12)\n",
    "        ax1.title.set_text('High Clips Exp %s' % j)\n",
    "        \n",
    "        b=lrlmu_clip.iloc[j]['prediction_prob_mid'][i]\n",
    "        ax2.plot(b[:,1])\n",
    "        ax2.set_xlim(0,1000)\n",
    "        ax2.set_xlabel('Frame', fontsize=12)\n",
    "        ax2.title.set_text('Intermediate Clips Exp %s' % j)\n",
    "        \n",
    "        c=lrlmu_clip.iloc[j]['prediction_prob_low'][i]\n",
    "        ax3.plot(c[:,1])\n",
    "        ax3.set_xlim(0,1000)\n",
    "        ax3.set_xlabel('Frame', fontsize=12)\n",
    "        ax3.title.set_text('Low Clips Exp %s' % j)\n",
    "        \n",
    "        d=lrlmu_clip.iloc[j]['prediction_prob_random'][i]\n",
    "        ax4.plot(d[:,1])\n",
    "        ax4.set_xlim(0,1000)\n",
    "        ax4.set_xlabel('Frame', fontsize=12)\n",
    "        ax4.title.set_text('Random Clips Exp %s' % j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Without LMUs\n",
    "Plot decision value across timeline of each clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(20): # for each experiment create 1 plot    \n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=(15, 4.5))\n",
    "    for i in range(18): # for each clip plot 1 line\n",
    "        a=mlpraw_clip.iloc[j]['decision_high'][i]\n",
    "        ax1.plot(a[:,0])\n",
    "        ax1.set_xlim(0,1000)\n",
    "        ax1.set_ylabel('Decision Value', fontsize=12)\n",
    "        ax1.set_xlabel('Frame', fontsize=12)\n",
    "        ax1.title.set_text('High Clips Exp %s' % j)\n",
    "        \n",
    "        b=mlpraw_clip.iloc[j]['decision_mid'][i]\n",
    "        ax2.plot(b[:,0])\n",
    "        ax2.set_xlim(0,1000)\n",
    "        ax2.set_xlabel('Frame', fontsize=12)\n",
    "        ax2.title.set_text('Intermediate Clips Exp %s' % j)\n",
    "        \n",
    "        c=mlpraw_clip.iloc[j]['decision_low'][i]\n",
    "        ax3.plot(c[:,0])\n",
    "        ax3.set_xlim(0,1000)\n",
    "        ax3.set_xlabel('Frame', fontsize=12)\n",
    "        ax3.title.set_text('Low Clips Exp %s' % j)\n",
    "        \n",
    "        d=mlpraw_clip.iloc[j]['decision_random'][i]\n",
    "        ax4.plot(d[:,0])\n",
    "        ax4.set_xlim(0,1000)\n",
    "        ax4.set_xlabel('Frame', fontsize=12)\n",
    "        ax4.title.set_text('Random Clips Exp %s' % j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP With LMUs\n",
    "Plot decision value across timeline of each clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(20): # for each experiment create 1 plot    \n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=(15, 4.5))\n",
    "    for i in range(18): # for each clip plot 1 line\n",
    "        a=mlplmu_clip.iloc[j]['decision_high'][i]\n",
    "        ax1.plot(a[:,0])\n",
    "        ax1.set_xlim(0,1000)\n",
    "        ax1.set_ylabel('Decision Value', fontsize=12)\n",
    "        ax1.set_xlabel('Frame', fontsize=12)\n",
    "        ax1.title.set_text('High Clips Exp %s' % j)\n",
    "        \n",
    "        b=mlplmu_clip.iloc[j]['decision_mid'][i]\n",
    "        ax2.plot(b[:,0])\n",
    "        ax2.set_xlim(0,1000)\n",
    "        ax2.set_xlabel('Frame', fontsize=12)\n",
    "        ax2.title.set_text('Intermediate Clips Exp %s' % j)\n",
    "        \n",
    "        c=mlplmu_clip.iloc[j]['decision_low'][i]\n",
    "        ax3.plot(c[:,0])\n",
    "        ax3.set_xlim(0,1000)\n",
    "        ax3.set_xlabel('Frame', fontsize=12)\n",
    "        ax3.title.set_text('Low Clips Exp %s' % j)\n",
    "        \n",
    "        d=mlplmu_clip.iloc[j]['decision_random'][i]\n",
    "        ax4.plot(d[:,0])\n",
    "        ax4.set_xlim(0,1000)\n",
    "        ax4.set_xlabel('Frame', fontsize=12)\n",
    "        ax4.title.set_text('Random Clips Exp %s' % j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Plots of Summary Statistics for each Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "ax1.scatter(high_lrraw_summary[:,0],high_lrraw_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax1.scatter(low_lrraw_summary[:,0],low_lrraw_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax1.set_xlabel('Mean', fontsize=12)\n",
    "ax1.set_ylabel('STD', fontsize=12)\n",
    "ax1.legend(loc=(1,0))\n",
    "ax1.title.set_text('Mean and STD for High and Low Clips')\n",
    "\n",
    "ax2.scatter(high_lrraw_summary[:,0],high_lrraw_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax2.scatter(mid_lrraw_summary[:,0],mid_lrraw_summary[:,1], alpha=0.7, color='orange', label='intermediate')\n",
    "ax2.scatter(low_lrraw_summary[:,0],low_lrraw_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax2.scatter(random_lrraw_summary[:,0],random_lrraw_summary[:,1], alpha=0.7, color='blue', label='random')\n",
    "ax2.set_xlabel('Mean', fontsize=12)\n",
    "ax2.set_ylabel('STD', fontsize=12)\n",
    "ax2.legend(loc=(1,0))\n",
    "ax2.title.set_text('Mean and STD for All Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(high_lrraw_summary[:,0],high_lrraw_summary[:,1],high_lrraw_summary[:,2], alpha=0.7, color='black', label='high')\n",
    "ax.scatter(mid_lrraw_summary[:,0],mid_lrraw_summary[:,1],mid_lrraw_summary[:,2], alpha=0.7, color='orange', label='intermediate')\n",
    "ax.scatter(low_lrraw_summary[:,0],low_lrraw_summary[:,1],low_lrraw_summary[:,2], alpha=0.7, color='grey', label='low')\n",
    "ax.scatter(random_lrraw_summary[:,0],random_lrraw_summary[:,1],random_lrraw_summary[:,2], alpha=0.7, color='blue', label='random')\n",
    "ax.set_ylabel('STD', fontsize=12)\n",
    "ax.set_xlabel('Mean', fontsize=12)\n",
    "ax.set_zlabel('Skewness', fontsize=12)\n",
    "ax.legend(loc=(0.9,0))\n",
    "ax.title.set_text('Mean, STD and Skewness for All Clips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel Logistic Regression <br>\n",
    "How well can we (linearly) separate clip classes based on summary statistics? <br>\n",
    "First calculate baseline - how well would our classifier generates predictions by respecting the training sets class distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_lrraw[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_lrraw[:,4]\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X, y)\n",
    "dummy_clf.predict(X)\n",
    "\n",
    "print('Baseline Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "print('Score: ', dummy_clf.score(X, y))\n",
    "\n",
    "print(dummy_clf.classes_)\n",
    "y_pred = dummy_clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do it for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_lrraw[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_lrraw[:,4]\n",
    "\n",
    "print('Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "print('Score: ', clf.score(X, y))\n",
    "\n",
    "print(clf.classes_)\n",
    "y_pred = clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression With LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "ax1.scatter(high_lrlmu_summary[:,0], high_lrlmu_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax1.scatter(low_lrlmu_summary[:,0], low_lrlmu_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax1.set_xlabel('Mean', fontsize=12)\n",
    "ax1.set_ylabel('STD', fontsize=12)\n",
    "ax1.legend(loc=(1,0))\n",
    "ax1.title.set_text('Mean and STD for Goal and Noplay clips')\n",
    "\n",
    "ax2.scatter(high_lrlmu_summary[:,0], high_lrlmu_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax2.scatter(mid_lrlmu_summary[:,0], mid_lrlmu_summary[:,1], alpha=0.7, color='orange', label='intermediate')\n",
    "ax2.scatter(low_lrlmu_summary[:,0], low_lrlmu_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax2.scatter(random_lrlmu_summary[:,0],random_lrlmu_summary[:,1], alpha=0.7, color='blue', label='random')\n",
    "ax2.set_xlabel('Mean', fontsize=12)\n",
    "ax2.set_ylabel('STD', fontsize=12)\n",
    "ax2.legend(loc=(1,0))\n",
    "ax2.title.set_text('Mean and STD for All Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(high_lrlmu_summary[:,0],high_lrlmu_summary[:,1],high_lrlmu_summary[:,2], alpha=0.7, color='black', label='high')\n",
    "ax.scatter(mid_lrlmu_summary[:,0],mid_lrlmu_summary[:,1],mid_lrlmu_summary[:,2], alpha=0.7, color='orange', label='intermediate')\n",
    "ax.scatter(low_lrlmu_summary[:,0],low_lrlmu_summary[:,1],low_lrlmu_summary[:,2], alpha=0.7, color='grey', label='low')\n",
    "ax.scatter(random_lrlmu_summary[:,0],random_lrlmu_summary[:,1],random_lrlmu_summary[:,2], alpha=0.7, color='blue', label='random')\n",
    "ax.set_ylabel('STD', fontsize=12)\n",
    "ax.set_xlabel('Mean', fontsize=12)\n",
    "ax.set_zlabel('Skewness', fontsize=12)\n",
    "ax.legend(loc=(0.9,0))\n",
    "ax.title.set_text('Mean, STD and Skewness for All Clips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel Logistic Regression <br>\n",
    "How well can we (linearly) separate clip classes based on summary statistics? <br>\n",
    "First calculate baseline - how well would our classifier generates predictions by respecting the training sets class distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_lrlmu[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_lrlmu[:,4]\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X, y)\n",
    "dummy_clf.predict(X)\n",
    "\n",
    "print('Baseline Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "print('Score: ', dummy_clf.score(X, y))\n",
    "\n",
    "print(dummy_clf.classes_)\n",
    "y_pred = dummy_clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do it for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_lrlmu[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_lrlmu[:,4]\n",
    "\n",
    "print('Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "print('Score: ', clf.score(X, y))\n",
    "\n",
    "print(clf.classes_)\n",
    "y_pred = clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "ax1.scatter(high_mlpraw_summary[:,0],high_mlpraw_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax1.scatter(low_mlpraw_summary[:,0],low_mlpraw_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax1.set_xlabel('Mean', fontsize=12)\n",
    "ax1.set_ylabel('STD', fontsize=12)\n",
    "ax1.legend(loc=(1,0))\n",
    "ax1.title.set_text('Mean and STD for Goal and Noplay clips')\n",
    "\n",
    "ax2.scatter(high_mlpraw_summary[:,0],high_mlpraw_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax2.scatter(mid_mlpraw_summary[:,0],mid_mlpraw_summary[:,1], alpha=0.7, color='orange', label='intermediate')\n",
    "ax2.scatter(low_mlpraw_summary[:,0],low_mlpraw_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax2.scatter(random_mlpraw_summary[:,0],random_mlpraw_summary[:,1], alpha=0.7, color='blue', label='random')\n",
    "ax2.set_xlabel('Mean', fontsize=12)\n",
    "ax2.set_ylabel('STD', fontsize=12)\n",
    "ax2.legend(loc=(1,0))\n",
    "ax2.title.set_text('Mean and STD for All Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(high_mlpraw_summary[:,0],high_mlpraw_summary[:,1],high_mlpraw_summary[:,2], alpha=0.7, color='black', label='high')\n",
    "ax.scatter(mid_mlpraw_summary[:,0],mid_mlpraw_summary[:,1],mid_mlpraw_summary[:,2], alpha=0.7, color='orange', label='intermediate')\n",
    "ax.scatter(low_mlpraw_summary[:,0],low_mlpraw_summary[:,1],low_mlpraw_summary[:,2], alpha=0.7, color='grey', label='low')\n",
    "ax.scatter(random_mlpraw_summary[:,0],random_mlpraw_summary[:,1],random_mlpraw_summary[:,2], alpha=0.7, color='blue', label='random')\n",
    "ax.set_ylabel('STD', fontsize=12)\n",
    "ax.set_xlabel('Mean', fontsize=12)\n",
    "ax.set_zlabel('Skewness', fontsize=12)\n",
    "ax.legend(loc=(0.9,0))\n",
    "ax.title.set_text('Mean, STD and Skewness for All Clips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel Logistic Regression <br>\n",
    "How well can we (linearly) separate clip classes based on summary statistics? <br>\n",
    "First calculate baseline - how well would our classifier generates predictions by respecting the training sets class distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_mlpraw[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_mlpraw[:,4]\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X, y)\n",
    "dummy_clf.predict(X)\n",
    "\n",
    "print('Baseline Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "print('Score: ', dummy_clf.score(X, y))\n",
    "\n",
    "print(dummy_clf.classes_)\n",
    "y_pred = dummy_clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do it for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_mlpraw[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_mlpraw[:,4]\n",
    "\n",
    "print('Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "print('Score: ', clf.score(X, y))\n",
    "\n",
    "print(clf.classes_)\n",
    "y_pred = clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP With LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(15, 4.5))\n",
    "ax1.scatter(high_mlplmu_summary[:,0],high_mlplmu_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax1.scatter(low_mlplmu_summary[:,0],low_mlplmu_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax1.set_xlabel('Mean', fontsize=12)\n",
    "ax1.set_ylabel('STD', fontsize=12)\n",
    "ax1.legend(loc=(1,0))\n",
    "ax1.title.set_text('Mean and STD for Goal and Noplay clips')\n",
    "\n",
    "ax2.scatter(high_mlplmu_summary[:,0],high_mlplmu_summary[:,1], alpha=0.7, color='black', label='high')\n",
    "ax2.scatter(mid_mlplmu_summary[:,0],mid_mlplmu_summary[:,1], alpha=0.7, color='orange', label='intermediate')\n",
    "ax2.scatter(low_mlplmu_summary[:,0],low_mlplmu_summary[:,1], alpha=0.7, color='grey', label='low')\n",
    "ax2.scatter(random_mlplmu_summary[:,0],random_mlplmu_summary[:,1], alpha=0.7, color='blue', label='random')\n",
    "ax2.set_xlabel('Mean', fontsize=12)\n",
    "ax2.set_ylabel('STD', fontsize=12)\n",
    "ax2.legend(loc=(1,0))\n",
    "ax2.title.set_text('Mean and STD for All Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(high_mlplmu_summary[:,0],high_mlplmu_summary[:,1],high_mlplmu_summary[:,2], alpha=0.7, color='black', label='high')\n",
    "ax.scatter(mid_mlplmu_summary[:,0],mid_mlplmu_summary[:,1],mid_mlplmu_summary[:,2], alpha=0.7, color='orange', label='intermediate')\n",
    "ax.scatter(low_mlplmu_summary[:,0],low_mlplmu_summary[:,1],low_mlplmu_summary[:,2], alpha=0.7, color='grey', label='low')\n",
    "ax.scatter(random_mlplmu_summary[:,0],random_mlplmu_summary[:,1],random_mlplmu_summary[:,2], alpha=0.7, color='blue', label='random')\n",
    "ax.set_ylabel('STD', fontsize=12)\n",
    "ax.set_xlabel('Mean', fontsize=12)\n",
    "ax.set_zlabel('Skewness', fontsize=12)\n",
    "ax.legend(loc=(0.9,0))\n",
    "ax.title.set_text('Mean, STD and Skewness for All Clips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilabel Logistic Regression <br>\n",
    "How well can we (linearly) separate clip classes based on summary statistics? <br>\n",
    "First calculate baseline - how well would our classifier generates predictions by respecting the training sets class distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_mlplmu[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_mlplmu[:,4]\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X, y)\n",
    "dummy_clf.predict(X)\n",
    "\n",
    "print('Baseline Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "print('Score: ', dummy_clf.score(X, y))\n",
    "\n",
    "print(dummy_clf.classes_)\n",
    "y_pred = dummy_clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do it for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = summaries_mlplmu[:,:4]\n",
    "X = X.astype(np.float)\n",
    "y = summaries_mlplmu[:,4]\n",
    "\n",
    "print('Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "print('Score: ', clf.score(X, y))\n",
    "\n",
    "print(clf.classes_)\n",
    "y_pred = clf.predict(X)  \n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
